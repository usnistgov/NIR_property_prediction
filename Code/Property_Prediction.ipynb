{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633bd6f8-53a0-4690-93ad-a8681746fd5a",
   "metadata": {},
   "source": [
    "# Perform property prediction using multiple machine learning techniques\n",
    "\n",
    "Machine learning techniques include principle component regression, partial least squares regression, least absolute shrinkage and selection operator, linear regression, and random forest on 39 polyolefin samples, including 19 non-blended polymers, 11 HDPE/PP blends and 9 HDPE/LDPE blends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce75586-4405-489e-a42f-681aec8d4009",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c5e76-be51-49f9-b0d9-eb39ff7be92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.markers as pltmarkers\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# data handling\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# model performance evaluation\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a275d6-20c1-40b8-b2af-72f05c273a20",
   "metadata": {},
   "source": [
    "## Read spectra data and separate intensity and wavenumber into two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24574b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file list\n",
    "folderpath = \"../Data/NIR/\"\n",
    "joined_files = os.path.join(folderpath, \"*.csv\")\n",
    "\n",
    "joined_list = glob.glob(joined_files)\n",
    "\n",
    "# combine wavenumbers in one dataframe\n",
    "dfq = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(file, header=None, names=[file[len(folderpath) : -4]], usecols=[0])\n",
    "        for file in joined_list\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# combine intensities in one dataframe\n",
    "dfI = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(file, header=None, names=[file[len(folderpath) : -4]], usecols=[1])\n",
    "        for file in joined_list\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80eaf8",
   "metadata": {},
   "source": [
    "### Plot spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "for col in dfI.columns:\n",
    "    plt.plot(dfq[col], dfI[col], label=col)\n",
    "\n",
    "plt.xlabel(\"Wavenumber [cm$^{-1}$]\", fontsize=14)\n",
    "plt.ylabel(\"Intensity\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42831ec",
   "metadata": {},
   "source": [
    "### Check to make sure all wavenumbers are the same across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq = dfq.T.drop_duplicates().T\n",
    "if len(dfq.columns) == 1:\n",
    "    q = dfq.to_numpy()\n",
    "else:\n",
    "    print(\"Wavenumbers vary across samples. Code needs to be modified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c0a6b-1c00-4794-8bc1-f0a1d3a7701b",
   "metadata": {},
   "source": [
    "## RNV preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd28097-dc83-4f10-a6eb-434ab251b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNVpreprocessing(I):\n",
    "    \"\"\"Perform RNV preprocessing.\"\"\"\n",
    "\n",
    "    quart1 = np.percentile(I, 25)\n",
    "    quart3 = np.percentile(I, 75)\n",
    "\n",
    "    mask = np.logical_and(quart1 <= I, I <= quart3)\n",
    "\n",
    "    mean = I[mask].mean()\n",
    "    std = I[mask].std()\n",
    "\n",
    "    IRNV = (I - mean) / std\n",
    "\n",
    "    return IRNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e3406",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRNV = dfI.apply(RNVpreprocessing, axis=0)\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(5, 4))\n",
    "dfRNV.plot(legend=False)\n",
    "\n",
    "plt.xlabel(\"Wavenumber [cm$^{-1}$]\", fontsize=14)\n",
    "plt.ylabel(\"Intensity\", fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "RNVI = dfRNV.to_numpy().T\n",
    "nspectra = RNVI.shape[0]\n",
    "\n",
    "# export wavenumbers\n",
    "np.savetxt(\"../ModelData/RNV_wavenumbers.csv\", dfq, delimiter=\",\", header=\"Wavenumbers\")\n",
    "\n",
    "# export RNV intensities\n",
    "np.savetxt(\"../ModelData/RNV_intensities.csv\", RNVI, delimiter=\",\")\n",
    "\n",
    "column_names = dfI.columns.tolist()\n",
    "with open(\"../ModelData/RNV_column_names.txt\", \"w\") as f:\n",
    "    for col_name in column_names:\n",
    "        f.write(f\"{col_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd1e3a",
   "metadata": {},
   "source": [
    "## Read property data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94368422",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../Data/PropertyMeasurements.csv\"\n",
    "\n",
    "dfprop = pd.read_csv(file_path, usecols=[0, 1, 2, 3])\n",
    "\n",
    "# remove units for ease of use\n",
    "header = dfprop.columns.tolist()\n",
    "header = [label.split()[0] for label in header]\n",
    "dfprop.columns = header\n",
    "\n",
    "dfprop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd272b-0f4e-4912-a742-7d377639aeff",
   "metadata": {},
   "source": [
    "## Labeling polymer types by type based on file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c3619-1928-401a-93e1-8e778f2e34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of samples by removing replicas\n",
    "samples = sorted(list(set([file[:-2] for file in list(dfI.columns)])))\n",
    "\n",
    "labels = (\n",
    "    samples.copy()\n",
    ")  # labels is a copy of the samples list, which will be modified to hold the corresponding labels for each sample\n",
    "indices = np.arange(len(samples))\n",
    "labeldict = {\"HDPE\": 0, \"LDPE\": 1, \"LLDPE\": 2, \"PP\": 3, \"PE/PP blend\": 4, \"PE blend\": 5}\n",
    "\n",
    "# assign labels\n",
    "for i, single in enumerate(samples):\n",
    "    if \"L_\" in single:\n",
    "        labels[i] = \"PE blend\"\n",
    "    elif \"HDPE_\" in single:\n",
    "        labels[i] = \"PE/PP blend\"\n",
    "    elif \"MDPE\" in single:\n",
    "        labels[i] = \"LDPE\"\n",
    "    elif \"LLDPE\" in single:\n",
    "        labels[i] = \"LLDPE\"\n",
    "    elif \"LDPE\" in single:\n",
    "        labels[i] = \"LDPE\"\n",
    "    elif \"HDPE\" in single:\n",
    "        labels[i] = \"HDPE\"\n",
    "    elif \"PP\" in single:\n",
    "        labels[i] = \"PP\"\n",
    "    else:\n",
    "        print(\"Error.\")\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    print(samples[i], \"\\t\", labels[i], \"\\t\", labeldict[labels[i]])\n",
    "numlabels = np.array(\n",
    "    [labeldict[entry] for entry in labels]\n",
    ")  # convert a list of labels into an array of numerical labels\n",
    "\n",
    "np.savetxt(\"../ModelData/samples.txt\", samples, delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"../ModelData/labels.txt\", labels, delimiter=\",\", fmt=\"%s\")\n",
    "np.savetxt(\"../ModelData/numlabels.csv\", numlabels, delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd2173-75e3-4dc7-b380-621cadf7a6b2",
   "metadata": {},
   "source": [
    "### Define get data function for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170a18c-effc-4912-83f3-671836e3d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(index, samples, dfRNV, propvalues, proplabel):\n",
    "    \"\"\"Get X and y data based on indices.\"\"\"\n",
    "\n",
    "    # get X\n",
    "    samplelist = [samples[i] + \"_\" + str(j + 1) for i in index for j in range(6)]\n",
    "    X = dfRNV[samplelist].to_numpy().T\n",
    "\n",
    "    # get y\n",
    "    propdict = pd.Series(\n",
    "        propvalues, index=proplabel\n",
    "    ).to_dict()  # creating a dictionary (propdict) from a Pandas Series\n",
    "    prop = np.array(\n",
    "        [propdict[samples[i]] for i in index]\n",
    "    )  # retrieves the corresponding sample name from the samples list and uses it as a key to fetch the corresponding density value from the propdict dictionary\n",
    "    y = np.repeat(\n",
    "        prop, 6\n",
    "    )  # repeats each element of the prop array six times to match 6 spectra replicates\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eeffcc",
   "metadata": {},
   "source": [
    "## Centering and Normalization (additional preprocessing after RNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc43f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_and_normalize(Xtrain, Xtest):\n",
    "    \"\"\"Center and normalize the training and test data.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "    Xtest_scaled = scaler.transform(Xtest)\n",
    "\n",
    "    return Xtrain_scaled, Xtest_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946ddc9",
   "metadata": {},
   "source": [
    "# Define ML models for Property Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f8990",
   "metadata": {},
   "source": [
    "## Principal Component Analysis followed by Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCR(Xtrain, ytrain, Xtest, n):\n",
    "    \"\"\"Perform Principal Component Analysis followed by Regression.\"\"\"\n",
    "\n",
    "    # center and normalize data\n",
    "    Xtrain_scaled, Xtest_scaled = center_and_normalize(Xtrain, Xtest)\n",
    "\n",
    "    pca = PCA()\n",
    "    Xtrain_pca = pca.fit_transform(Xtrain_scaled)\n",
    "    Xtest_pca = pca.transform(Xtest_scaled)\n",
    "\n",
    "    # perform regression on train\n",
    "    regression_model_pcr = LinearRegression()\n",
    "    regression_model_pcr.fit(Xtrain_pca[:, :n], ytrain)\n",
    "\n",
    "    # evaluate\n",
    "    ytest_pred_pcr = regression_model_pcr.predict(Xtest_pca[:, :n])\n",
    "\n",
    "    return ytest_pred_pcr, regression_model_pcr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c64161",
   "metadata": {},
   "source": [
    "## Partical Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fa909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLSR(Xtrain, ytrain, Xtest, n):\n",
    "    \"\"\"Perform Partical Least Squares Regression.\"\"\"\n",
    "\n",
    "    # center and normalize data\n",
    "    Xtrain_scaled, Xtest_scaled = center_and_normalize(Xtrain, Xtest)\n",
    "\n",
    "    pls = PLSRegression(n_components=n)\n",
    "    pls.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "    # evaluate\n",
    "    ytest_pred_plsr = pls.predict(Xtest_scaled)\n",
    "\n",
    "    return ytest_pred_plsr, pls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abd905",
   "metadata": {},
   "source": [
    "## Least Absolute Shrinkage and Selection Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LASSO(Xtrain, ytrain, Xtest, alpha):\n",
    "    \"\"\"Perform Lasso Regression. alpha determines the regularization strength.\"\"\"\n",
    "\n",
    "    # center and normalize data\n",
    "    Xtrain_scaled, Xtest_scaled = center_and_normalize(Xtrain, Xtest)\n",
    "\n",
    "    lasso = Lasso(alpha=alpha, max_iter=50000)\n",
    "    lasso.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "    # evaluate\n",
    "    ytest_pred = lasso.predict(Xtest_scaled)\n",
    "\n",
    "    return ytest_pred, lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587b67e1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(Xtrain, ytrain, Xtest, n_estimators, max_features):\n",
    "    \"\"\"Perform Random Forest Regression.\n",
    "\n",
    "    n_estimators is the number of trees and max_features is\n",
    "    the size of the random subsets of features to consider when splitting a node.\n",
    "    The lower the greater the reduction of variance, but also the greater the increase in bias.\n",
    "    \"\"\"\n",
    "\n",
    "    # center and normalize data\n",
    "    Xtrain_scaled, Xtest_scaled = center_and_normalize(Xtrain, Xtest)\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, max_features=max_features, random_state=0\n",
    "    )\n",
    "    rf.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "    # evaluate\n",
    "    ytest_pred_rf = rf.predict(Xtest_scaled)\n",
    "\n",
    "    return ytest_pred_rf, rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ba680-8cae-4bdb-90d9-b6855c9715b4",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7b0b1-c7ec-4976-9958-d3d2b5e82535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(Xtrain, ytrain, Xtest):\n",
    "    \"\"\"Perform linear regression on NIR spectra.\"\"\"\n",
    "\n",
    "    # center and normalize data\n",
    "    Xtrain_scaled, Xtest_scaled = center_and_normalize(Xtrain, Xtest)\n",
    "\n",
    "    # train the Linear Regression model\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "    # evaluate\n",
    "    ytest_pred = lr_model.predict(Xtest_scaled)\n",
    "\n",
    "    return ytest_pred, lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93138f6d",
   "metadata": {},
   "source": [
    "# Set up training machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256097ae",
   "metadata": {},
   "source": [
    "## Nested cross fold for training models including hyperparamter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d860c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NestedCrossFold(\n",
    "    dfRNV,\n",
    "    samples,\n",
    "    propvalues,\n",
    "    proplabel,\n",
    "    MLmodel,\n",
    "    param,\n",
    "    indices,\n",
    "    numlabels,\n",
    "    savefile=None,\n",
    "):\n",
    "    \"\"\"Perform nested cross fold to perfrom hyperparameter optimization and train machine learning models.\"\"\"\n",
    "\n",
    "    results = {\n",
    "        \"test_r2_scores\": [],\n",
    "        \"train_r2_scores\": [],\n",
    "        \"test_rmse_scores\": [],\n",
    "        \"train_rmse_scores\": [],\n",
    "        \"best_params\": [],  # store full best parameters for each outer fold\n",
    "        \"val_r2_scores\": defaultdict(list),\n",
    "        \"best_hyperparameters\": [],  # store the key hyperparameter for each model type\n",
    "        \"num_parameters\": [],  # store the number of non-zero coefficients for LASSO\n",
    "    }\n",
    "\n",
    "    model_name = MLmodel.__name__\n",
    "\n",
    "    val_rmse_scores = defaultdict(list)\n",
    "\n",
    "    # parameter keys to track for each model type\n",
    "    param_keys = {\"PLSR\": \"n\", \"PCR\": \"n\", \"LASSO\": \"alpha\", \"RF\": \"n_estimators\"}\n",
    "\n",
    "    key_param = param_keys.get(model_name, None)\n",
    "\n",
    "    # outer fold\n",
    "    skf_out = sklearn.model_selection.StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=0\n",
    "    )\n",
    "\n",
    "    print(f\"Running {model_name} with nested cross-validation\")\n",
    "    print(\"Indices are:\", indices)\n",
    "\n",
    "    for i, (train_out_index, test_out_index) in enumerate(\n",
    "        skf_out.split(indices, numlabels)\n",
    "    ):\n",
    "\n",
    "        numlabels_train_out = numlabels[train_out_index]\n",
    "        numlabels_test_out = numlabels[test_out_index]\n",
    "        train_out_index_fix = indices[train_out_index]\n",
    "        test_out_index_fix = indices[test_out_index]\n",
    "\n",
    "        # inner fold\n",
    "        skf_in = sklearn.model_selection.StratifiedKFold(\n",
    "            n_splits=5, shuffle=True, random_state=0\n",
    "        )\n",
    "\n",
    "        # track performance for each parameter set across all inner folds\n",
    "        param_performance = defaultdict(list)\n",
    "\n",
    "        for j, (train_in_index, test_in_index) in enumerate(\n",
    "            skf_in.split(train_out_index_fix, numlabels_train_out)\n",
    "        ):\n",
    "\n",
    "            train_in_index_fix = train_out_index_fix[train_in_index]\n",
    "            test_in_index_fix = train_out_index_fix[test_in_index]\n",
    "\n",
    "            # get data for training the models\n",
    "            Xtrain, ytrain = getXy(\n",
    "                train_in_index_fix, samples, dfRNV, propvalues, proplabel\n",
    "            )\n",
    "            Xval, yval = getXy(test_in_index_fix, samples, dfRNV, propvalues, proplabel)\n",
    "\n",
    "            for params in param:\n",
    "                # create a parameter identifier\n",
    "                param_id = str(params)\n",
    "\n",
    "                # train and evaluate model\n",
    "                yval_pred, _ = MLmodel(Xtrain, ytrain, Xval, **params)\n",
    "\n",
    "                r2 = r2_score(yval, yval_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(yval, yval_pred))\n",
    "\n",
    "                # store this parameter set's performance\n",
    "                param_performance[param_id].append({\"rmse\": rmse, \"params\": params})\n",
    "\n",
    "                # keep a record of validation performance metrics, analyze how a specific hyperparameter affects model performance\n",
    "                if key_param and key_param in params:\n",
    "                    key_value = params[key_param]\n",
    "                    val_rmse_scores[key_value].append(rmse)\n",
    "\n",
    "        # calculate average performance for each parameter set\n",
    "        avg_performance = {}\n",
    "        for param_id, performances in param_performance.items():\n",
    "            avg_rmse = np.mean([p[\"rmse\"] for p in performances])\n",
    "            avg_performance[param_id] = {\n",
    "                \"avg_rmse\": avg_rmse,\n",
    "                \"params\": performances[0][\"params\"],\n",
    "            }\n",
    "\n",
    "        # find best parameter set based on lowest average RMSE\n",
    "        best_param_id = min(\n",
    "            avg_performance, key=lambda k: avg_performance[k][\"avg_rmse\"]\n",
    "        )\n",
    "        best_params = avg_performance[best_param_id][\"params\"]\n",
    "        best_avg_rmse = avg_performance[best_param_id][\"avg_rmse\"]\n",
    "\n",
    "        print(f\"Outer fold {i}: Best parameters with avg RMSE {best_avg_rmse:.4f}\")\n",
    "\n",
    "        # store the best parameters for this outer fold\n",
    "        results[\"best_params\"].append(best_params)\n",
    "\n",
    "        # store the key hyperparameter\n",
    "        if key_param and key_param in best_params:\n",
    "            results[\"best_hyperparameters\"].append(best_params[key_param])\n",
    "            print(f\"Best {key_param} for {model_name}: {best_params[key_param]}\")\n",
    "\n",
    "        # **************** below test the models on the test sets on outer loops ********************\n",
    "\n",
    "        Xtrain_out, ytrain_out = getXy(\n",
    "            train_out_index_fix, samples, dfRNV, propvalues, proplabel\n",
    "        )\n",
    "        Xtest_out, ytest_out = getXy(\n",
    "            test_out_index_fix, samples, dfRNV, propvalues, proplabel\n",
    "        )\n",
    "\n",
    "        # get the model predictions and count parameters efficiently\n",
    "        if model_name == \"LASSO\":\n",
    "            ytest_pred, modellasso = MLmodel(\n",
    "                Xtrain_out, ytrain_out, Xtest_out, **best_params\n",
    "            )\n",
    "\n",
    "            # count non-zero coefficients\n",
    "            num_nonzero = np.sum(modellasso.coef_ != 0)\n",
    "            total_features = len(modellasso.coef_)\n",
    "            results[\"num_parameters\"].append(num_nonzero)\n",
    "\n",
    "            print(\n",
    "                f\"LASSO with alpha={best_params['alpha']} uses {num_nonzero} out of {total_features} features\"\n",
    "            )\n",
    "\n",
    "        elif model_name == \"PCR\":\n",
    "            ytest_pred, modelpcr = MLmodel(\n",
    "                Xtrain_out, ytrain_out, Xtest_out, **best_params\n",
    "            )\n",
    "            n_components = best_params[\"n\"]\n",
    "            results[\"num_parameters\"].append(n_components)\n",
    "            print(f\"PCR model using {n_components} principal components\")\n",
    "\n",
    "        elif model_name == \"PLSR\":\n",
    "            ytest_pred, plsrmodel = MLmodel(\n",
    "                Xtrain_out, ytrain_out, Xtest_out, **best_params\n",
    "            )\n",
    "            n_components = best_params[\"n\"]\n",
    "            results[\"num_parameters\"].append(n_components)\n",
    "            print(f\"PLSR model using {n_components} components\")\n",
    "\n",
    "        elif model_name == \"RF\":\n",
    "            ytest_pred, modelrf = MLmodel(\n",
    "                Xtrain_out, ytrain_out, Xtest_out, **best_params\n",
    "            )\n",
    "\n",
    "            # extract feature importances and count how many features were used\n",
    "            importances = modelrf.feature_importances_\n",
    "            num_important_features = np.count_nonzero(importances > 1e-6)\n",
    "            results[\"num_parameters\"].append(num_important_features)\n",
    "            print(f\"RF model using {num_important_features} important features\")\n",
    "\n",
    "        elif model_name == \"LR\":\n",
    "            ytest_pred, modellr = MLmodel(\n",
    "                Xtrain_out, ytrain_out, Xtest_out, **best_params\n",
    "            )\n",
    "            num_features = Xtrain_out.shape[1]  # total number of input features\n",
    "            results[\"num_parameters\"].append(num_features)\n",
    "            print(f\"LR model using all {num_features} features\")\n",
    "\n",
    "        test_r2 = r2_score(ytest_out, ytest_pred)\n",
    "        test_rmse = np.sqrt(mean_squared_error(ytest_out, ytest_pred))\n",
    "        print(\n",
    "            f\"Test R^2 score for outer fold {i}: {test_r2:.4f}, Test RMSE: {test_rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "        ytrain_pred, savedmodel = MLmodel(\n",
    "            Xtrain_out, ytrain_out, Xtrain_out, **best_params\n",
    "        )\n",
    "\n",
    "        # save the results\n",
    "        if savefile != None:\n",
    "\n",
    "            np.savetxt(\n",
    "                savefile + \"labels_train_\" + str(i) + \".csv\",\n",
    "                numlabels_train_out,\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "            np.savetxt(\n",
    "                savefile + \"labels_test_\" + str(i) + \".csv\",\n",
    "                numlabels_test_out,\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "\n",
    "            np.savetxt(\n",
    "                savefile + \"X_train_\" + str(i) + \".csv\", Xtrain_out, delimiter=\",\"\n",
    "            )\n",
    "            np.savetxt(savefile + \"X_test_\" + str(i) + \".csv\", Xtest_out, delimiter=\",\")\n",
    "            np.savetxt(\n",
    "                savefile + \"y_train_\" + str(i) + \".csv\", ytrain_out, delimiter=\",\"\n",
    "            )\n",
    "            np.savetxt(savefile + \"y_test_\" + str(i) + \".csv\", ytest_out, delimiter=\",\")\n",
    "            np.savetxt(\n",
    "                savefile + \"ypred_\" + model_name + \"_train_\" + str(i) + \".csv\",\n",
    "                ytrain_pred,\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "            np.savetxt(\n",
    "                savefile + \"ypred_\" + model_name + \"_test_\" + str(i) + \".csv\",\n",
    "                ytest_pred,\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "\n",
    "            if model_name in [\"PLSR\", \"PCR\", \"LASSO\", \"LR\"]:\n",
    "\n",
    "                np.savetxt(\n",
    "                    savefile + model_name + \"_coef_\" + str(i) + \".csv\",\n",
    "                    savedmodel.coef_,\n",
    "                    delimiter=\",\",\n",
    "                )\n",
    "                np.savetxt(\n",
    "                    savefile + model_name + \"_intercept_\" + str(i) + \".csv\",\n",
    "                    [savedmodel.intercept_],\n",
    "                    delimiter=\",\",\n",
    "                )\n",
    "\n",
    "        train_r2 = r2_score(ytrain_out, ytrain_pred)\n",
    "        train_rmse = np.sqrt(mean_squared_error(ytrain_out, ytrain_pred))\n",
    "        print(\n",
    "            f\"Train R^2 score for outer fold {i}: {train_r2:.4f}, Train RMSE: {train_rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "        results[\"test_r2_scores\"].append(test_r2)\n",
    "        results[\"test_rmse_scores\"].append(test_rmse)\n",
    "        results[\"train_r2_scores\"].append(train_r2)\n",
    "        results[\"train_rmse_scores\"].append(train_rmse)\n",
    "\n",
    "    # calculate and print average performance across all outer folds\n",
    "    avg_test_r2 = np.mean(results[\"test_r2_scores\"])\n",
    "    avg_test_rmse = np.mean(results[\"test_rmse_scores\"])\n",
    "    avg_train_r2 = np.mean(results[\"train_r2_scores\"])\n",
    "    avg_train_rmse = np.mean(results[\"train_rmse_scores\"])\n",
    "\n",
    "    print(f\"\\nAverage performance for {model_name}:\")\n",
    "    print(f\"Test R² = {avg_test_r2:.4f} ± {np.std(results['test_r2_scores']):.4f}\")\n",
    "    print(\n",
    "        f\"Test RMSE = {avg_test_rmse:.4f} ± {np.std(results['test_rmse_scores']):.4f}\"\n",
    "    )\n",
    "    print(\"Test RMSEs =\", results[\"test_rmse_scores\"])\n",
    "    print(f\"Train R² = {avg_train_r2:.4f} ± {np.std(results['train_r2_scores']):.4f}\")\n",
    "    print(\n",
    "        f\"Train RMSE = {avg_train_rmse:.4f} ± {np.std(results['train_rmse_scores']):.4f}\"\n",
    "    )\n",
    "    print(\"Train RMSEs =\", results[\"test_rmse_scores\"])\n",
    "\n",
    "    # calculate average number of parameters\n",
    "    if results[\"num_parameters\"]:\n",
    "        avg_num_params = np.mean(results[\"num_parameters\"])\n",
    "        print(f\"Average number of features used by {model_name}: {avg_num_params:.1f}\")\n",
    "\n",
    "    return results, val_rmse_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa0e36",
   "metadata": {},
   "source": [
    "## Set options for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_plsr = [{\"n\": n} for n in range(1, 31)]\n",
    "param_pcr = [{\"n\": n} for n in range(1, 31)]\n",
    "param_lasso = [\n",
    "    {\"alpha\": alpha} for alpha in np.logspace(-4, 0, 10)\n",
    "]  # 10 numbers from 10(-4) to 10(0)\n",
    "param_rf = [\n",
    "    {\"n_estimators\": n, \"max_features\": f}\n",
    "    for n in [20, 50, 100, 200, 300]\n",
    "    for f in [2, 5, 10, 15, 20]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ddd99-dcfe-4821-a6c8-b3d4bcef4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist = [PLSR, PCR, LASSO, LR, RF]\n",
    "paramlist = [param_plsr, param_pcr, param_lasso, [{}], param_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe8c62",
   "metadata": {},
   "source": [
    "# Loop through the properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b448c01",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be6834-b3f9-4547-bdb6-53036604822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_den = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Mean Test RMSE\",\n",
    "        \"Std Test RMSE\",\n",
    "        \"Mean Train RMSE\",\n",
    "        \"Std Train RMSE\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, model in enumerate(modellist):\n",
    "\n",
    "    results, _ = NestedCrossFold(\n",
    "        dfRNV,\n",
    "        samples,\n",
    "        dfprop.density.values,\n",
    "        dfprop.label,\n",
    "        model,\n",
    "        paramlist[i],\n",
    "        indices,\n",
    "        numlabels,\n",
    "        \"../ModelData/density/\",\n",
    "    )\n",
    "    print(model.__name__, \"Results:\", results)\n",
    "\n",
    "    results_df_den.loc[i] = [\n",
    "        model.__name__,\n",
    "        np.mean(results[\"test_rmse_scores\"]),\n",
    "        np.std(results[\"test_rmse_scores\"]),\n",
    "        np.mean(results[\"train_rmse_scores\"]),\n",
    "        np.std(results[\"train_rmse_scores\"]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed98b5-fdab-4059-b42a-e31f61dc0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_den.to_csv(\"../ModelData/density/density_results.csv\", index=False)\n",
    "results_df_den.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249f633",
   "metadata": {},
   "source": [
    "## Crystallinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afcccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single out non-blended samples only\n",
    "mask_homopolymers = np.isin(numlabels, [0, 1, 2, 3])\n",
    "indiceshomopolymer = indices[mask_homopolymers]\n",
    "numlabelshomopolymer = numlabels[mask_homopolymers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_crys = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Mean Test RMSE\",\n",
    "        \"Std Test RMSE\",\n",
    "        \"Mean Train RMSE\",\n",
    "        \"Std Train RMSE\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, model in enumerate(modellist):\n",
    "\n",
    "    results, _ = NestedCrossFold(\n",
    "        dfRNV,\n",
    "        samples,\n",
    "        dfprop.crystallinity.values,\n",
    "        dfprop.label,\n",
    "        model,\n",
    "        paramlist[i],\n",
    "        indiceshomopolymer,\n",
    "        numlabelshomopolymer,\n",
    "        \"../ModelData/crystallinity/\",\n",
    "    )\n",
    "    print(model.__name__, \"Results:\", results)\n",
    "\n",
    "    results_df_crys.loc[i] = [\n",
    "        model.__name__,\n",
    "        np.mean(results[\"test_rmse_scores\"]),\n",
    "        np.std(results[\"test_rmse_scores\"]),\n",
    "        np.mean(results[\"train_rmse_scores\"]),\n",
    "        np.std(results[\"train_rmse_scores\"]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227cd59-aa4f-4600-86bb-3852dffd411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_crys.to_csv(\n",
    "    \"../ModelData/crystallinity/crystallinity_results.csv\", index=False\n",
    ")\n",
    "results_df_crys.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee097a4",
   "metadata": {},
   "source": [
    "## Short Chain Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57729bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_scb = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Mean Test RMSE\",\n",
    "        \"Std Test RMSE\",\n",
    "        \"Mean Train RMSE\",\n",
    "        \"Std Train RMSE\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for i, model in enumerate(modellist):\n",
    "\n",
    "    results, _ = NestedCrossFold(\n",
    "        dfRNV,\n",
    "        samples,\n",
    "        dfprop.SCB.values,\n",
    "        dfprop.label,\n",
    "        model,\n",
    "        paramlist[i],\n",
    "        indices,\n",
    "        numlabels,\n",
    "        \"../ModelData/SCB/\",\n",
    "    )\n",
    "    print(model.__name__, \"Results:\", results)\n",
    "\n",
    "    results_df_scb.loc[i] = [\n",
    "        model.__name__,\n",
    "        np.mean(results[\"test_rmse_scores\"]),\n",
    "        np.std(results[\"test_rmse_scores\"]),\n",
    "        np.mean(results[\"train_rmse_scores\"]),\n",
    "        np.std(results[\"train_rmse_scores\"]),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b50df1-7b3c-492a-87e2-b44c2e4cb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_scb.to_csv(\"../ModelData/scb/scb_results.csv\", index=False)\n",
    "results_df_scb.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
